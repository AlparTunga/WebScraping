from urllib.parse import urljoin
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import pandas as pd
import time
import requests
from concurrent.futures import ThreadPoolExecutor
from webdriver_manager.chrome import ChromeDriverManager

# ğŸš€ TarayÄ±cÄ±yÄ± hÄ±zlÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in Selenium ayarlarÄ±
options = Options()
options.add_argument("--headless")  # Arka planda Ã§alÄ±ÅŸtÄ±r (gÃ¶rÃ¼nmez)
options.add_argument("--disable-gpu")
options.add_argument("--no-sandbox")

# WebDriver baÅŸlat
service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service)

# Ã‡ekilecek kategori URL'leri
categories = [
    "https://www.robotistan.com/arduino",
    "https://www.robotistan.com/raspberry-pi-turkiye",
    "https://www.robotistan.com/3d",
    "https://www.robotistan.com/egitici-setler",
    "https://www.robotistan.com/cocuklar-icin-robotik-kodlama",
    "https://www.robotistan.com/gelistirme-kartlari-1",
    "https://www.robotistan.com/elektronik-kart-modul",
    "https://www.robotistan.com/motor",
    "https://www.robotistan.com/sensor",
    "https://www.robotistan.com/guc-kaynagi-batarya",
    "https://www.robotistan.com/prototipleme-lehim",
    "https://www.robotistan.com/kablosuz-haberlesme",
    "https://www.robotistan.com/elektronik-komponent",
    "https://www.robotistan.com/mekanik",
    "https://www.robotistan.com/teker",
    "https://www.robotistan.com/olcu-test",
    "https://www.robotistan.com/arac-gerec",
    "https://www.robotistan.com/drone",
    "https://www.robotistan.com/outlet",
    "https://www.robotistan.com/kitap"
    "https://www.robotistan.com/robot-yarismalari"
]

# Ã‡ekilen verileri saklamak iÃ§in liste
data = []

# ğŸ“Œ Sayfa kaydÄ±rmayÄ± optimize eden fonksiyon
def scroll_page(driver):
    scroll_pause_time = 3
    screen_height = driver.execute_script("return window.innerHeight;")
    i = 1
    while True:
        driver.execute_script(f"window.scrollTo(0, {screen_height * i});")
        time.sleep(scroll_pause_time)
        i += 1
        new_height = driver.execute_script("return document.body.scrollHeight")
        if screen_height * i >= new_height:
            break

# ğŸŒ Kategori iÃ§indeki tÃ¼m Ã¼rÃ¼nleri Ã§ek
for category_url in categories:
    driver.get(category_url)
    time.sleep(3)  # SayfanÄ±n yÃ¼klenmesini bekle

    # SayfayÄ± kaydÄ±rarak tÃ¼m Ã¼rÃ¼nleri yÃ¼kle
    scroll_page(driver)
    
    # Sayfa kaynaÄŸÄ±nÄ± Ã§ek
    soup = BeautifulSoup(driver.page_source, "html.parser")
    
    # ÃœrÃ¼nleri seÃ§
    products = soup.select(".product-item")
    
    if not products:
        print(f"{category_url} kategorisinde Ã¼rÃ¼n bulunamadÄ±.")
        continue

    product_urls = []
    for product in products:
        # ÃœrÃ¼n adÄ±
        name = product.select_one(".product-title").get_text(strip=True)
        
        # ÃœrÃ¼n fiyatÄ±
        price = product.select_one(".product-price").get_text(strip=True) if product.select_one(".product-price") else "Fiyat bilgisi yok"
        
        # ÃœrÃ¼n URL'si
        relative_url = product.select_one("a")["href"]
        product_url = urljoin("https://www.robotistan.com", relative_url)  # âœ… URL'yi doÄŸru birleÅŸtir
        
        print(f"ÃœrÃ¼n URL: {product_url}")  # Debug iÃ§in URL kontrolÃ¼
        
        product_urls.append((name, price, product_url, category_url))

    # ğŸš€ Ã‡oklu iÅŸlem ile Ã¼rÃ¼n detaylarÄ±nÄ± Ã§ek
    def fetch_product_details(product_info):
        name, price, product_url, category_url = product_info
        headers = {"User-Agent": "Mozilla/5.0"}
        
        try:
            time.sleep(1)  # Web sitesinin engellememesi iÃ§in bekleme sÃ¼resi
            response = requests.get(product_url, headers=headers, timeout=10)
            response.raise_for_status()  # HTTP hatalarÄ±nÄ± yakala
        except requests.exceptions.RequestException as e:
            print(f"Hata: {e}")
            return None

        # Kategori ismi
        category_name = category_url.split("/")[-1]

        return {
            "Kategori": category_name,
            "ÃœrÃ¼n AdÄ±": name,
            "Fiyat": price,
            "URL": product_url,
            "Stok": "Stok bilgisi yok"
        }
    
    # ğŸš€ Paralel iÅŸlem (5 Ã¼rÃ¼n aynÄ± anda Ã§ekilir)
    with ThreadPoolExecutor(max_workers=5) as executor:
        results = list(executor.map(fetch_product_details, product_urls))
        data.extend(filter(None, results))  # Hata alan sonuÃ§larÄ± filtrele

# TarayÄ±cÄ±yÄ± kapat
driver.quit()

# Verileri Excel'e kaydet
df = pd.DataFrame(data)
df.to_excel("robotistan_tum_urunler.xlsx", index=False)
print("Veriler Excel dosyasÄ±na kaydedildi.")
